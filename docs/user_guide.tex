\documentclass[]{report}
\usepackage[margin=0.5in]{geometry}
\usepackage{enumitem}
\usepackage{alltt}  
\usepackage{hyperref}


\setdescription{leftmargin=\parindent,labelindent=\parindent,style=sameline}

\begin{document}

\title{Etkin Lab's Analysis Pipeline User's guide}
\author{Brian Patenaude}
\date{\today}
\maketitle
\begin{chapter}{Overview and Setup}
\begin{section}{Introduction}
Our  {\it analysis pipeline} is merely a bash script that bring together our structural and functional processing stream. It brings together components of FSL and SPM as well as integrates some custom code (typically implemented in C++).  
\end{section}
\begin{section}{Software requirements.}

This pipeline is for use on OSX or linux (tested on CentOS/RedHat). It requires the installation of FSL and SPM8. There will be some adjustments to the SPM8 configuration for our purposes. For OSX, it requires a version of readlink that is consistent with linux (i.e. has the -f option).

\end{section}

\begin{section}{Installation}
\begin{subsection}{Getting the data}
If you are reading this, you should already have access to the {\bf \it analysis\_pipeline} git repository that is hosted on \url{www.bitbucket.org}. The first step is to clone the repository into a local folder. The location is up to you, however, if you are planning to parallelize the jobs on a grid, it should by copied to a centralized location. The follow command will clone the repository, 

\begin{alltt}
\hspace*{0.5in} 	git clone https://bitbucket.org/bmpatena/analysis_pipeline
\end{alltt}

This will create a directory with an assortment of files in it needed for you to run the pipeline. Now it's time to setup your environment variables.

\end{subsection}
\begin{subsection}{Setting Up Environment }
It is assumed at this point that FSL has been installed and you environment has been setup. I've set these environments computer wide by editing /etc/profile. Otherwise, you can add to you personal profile. From a lab management perspective, the former facilitate consistency across all users.

\begin{alltt}
#location of the install 
export ANALYSIS_PIPE_DIR=/PATH_TO_SRC/analysis_pipeline/
export PATH=\${ANALYSIS_PIPE_DIR}:\${PATH}

#location of SPM install used for pipeline. 
export SPM8DIR=/Applications/spm8_sge
#fink
source /sw/bin/init.sh
\end{alltt}
{Some Notes}
\begin{itemize}
	\item  I use a local copy of SPM for performance issues with network copy; may not be an issue for you.
	\item  SPM image IO is not very friendly with network file system, this may be a cause of slow down if too many parallel instances exist.
	\item {\it source /sw/bin/init.sh} is only need for OSX. fink is used to install a version of readlink that is consistent with linux.  
\end{itemize}
\end{subsection}

\end{section}



\end{chapter}
\begin{chapter}{Quick Start Guide }

\begin{section}{Common options}
The basic options are those which I've found that most people use most frequently. They've been taken from scripts used from analyses that we have performed. For clarity I've used the image extensions in the examples, but they are not necessary.
%\setlist[itemize]{leftmargin=2in}
\begin{description}
	\item [-func\_data {\it func\_4D}] :  Proceeded by the 4D functional data (EPI or spiral).
	\item [ -t1 {\it im\_t1}]  : Proceeded by the highres structural image (T1 weighted). 
	\item [-reg\_info] : Optional, specified to use existing structural analysis folder. Proceeded by the structural analysis directory.
	\item [-design] : Proceeded by a Matlab .mat file of the design matrix. The internal structure is that specified by SPM.
	\item [-spm\_contrast] : Proceeded by an SPM contrast file (.m file).
	\item [-output\_extension {\it Analysis}] : Proceed by the extension that will be used for the output. It combined the name  
						\hspace*{1cm} specified by {\bf -func\_data} and append a "." plus whatever extensions. "+"  characters will be prepended in the case 
						\hspace*{1cm} the directory exists. e.g {\it func\_4D.Analysis}.
	\item[-model\_name {\it ModelName}] : Proceed by a name. A folder, {\it ModelName.spm} will be created in the output directory, this contains the final SPM analysis.
	\item[-motion] : No arguments. This options indicates to the pipeline to include motion regressors first level model.
	\item[-tr] : Proceeded by a number. The number is the TR from the acquisition sequence in seconds(time between time points).
	\item[-deleteVolumes] : Proceeded by an integer. The number of volumes to be deleted from the beginning of the time series.
\end{description}
\end{section}
\begin{section}{Running Structural Analysis}
I typically run the structural analyses as a separate stage. This is done for 2 reasons: 1) To be able to QC the registration prior to proceeding with first level models. 2) With multiple functional tasks, each can just reference (and link to) this analysis. This save a lot of computation time. 

To run the structural analysis, 
\begin{alltt}
analysis_pipeline.sh -struct_only -t1 subjectID\_struct\_t1.nii.gz  -output\_extension struct\_only
\end{alltt}



\end{section}

\begin{section}{Run a basic first level analysis}
\
\begin{alltt}
analysis\_pipeline.sh  -func\_data <fmri\_4D.nii.gz>   -t1 <subjectID\_struct\_t1.nii.gz>  \textbackslash \\
\hspace*{0.5in} -reg\_info <subjectID\_struct\_t1.struct\_only> -design <spm\_design\_matrix.mat> \textbackslash  \\
\hspace*{0.5in} -spm\_contrast  <spm\_contrast\_file.m> -model\_name <name\_of\_model> \textbackslash   \\
\hspace*{0.5in} -output\_extension <analysis\_directory\_extension>  -motion -tr <TR> \textbackslash  \\
\hspace*{0.5in} -deleteVolumes <Number\_of\_Volumes\_to\_Delete>
\end{alltt}
{Some Notes}
\begin{itemize}
	\item  The SPM design matrix should already account for the volumes to be deleted.
\end{itemize}

\end{section}

\end{chapter}

\begin{chapter}{Guide to Data Structure and Files}

\end{chapter}

\end{document}